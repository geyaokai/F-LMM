# ğŸ”§ ä¿®å¤ï¼šQwen2.5-VL Vision Tokens é—®é¢˜

## ğŸ“‹ æ–°é—®é¢˜

ç»è¿‡ä¹‹å‰çš„ä¿®å¤åï¼Œè®­ç»ƒå‡ºç°äº†æ–°çš„é”™è¯¯ï¼š

```
ValueError: Image features and image tokens do not match: tokens: 0, features 252
ValueError: Image features and image tokens do not match: tokens: 0, features 391
```

**è¿™æ˜¯å¥½æ¶ˆæ¯ï¼** ä¹‹å‰çš„ `RuntimeError` å·²ç»è§£å†³äº†ã€‚

## ğŸ” é—®é¢˜åˆ†æ

### é”™è¯¯å«ä¹‰

- `tokens: 0` - `input_ids` ä¸­**æ²¡æœ‰**å›¾åƒç›¸å…³çš„ç‰¹æ®Š token
- `features 252/391` - æ¨¡å‹ç”Ÿæˆäº†å›¾åƒç‰¹å¾

### æ ¹æœ¬åŸå› 

Qwen2.5-VL éœ€è¦åœ¨ `input_ids` ä¸­åŒ…å«ç‰¹æ®Šçš„ **vision tokens**ï¼š
- `<|vision_start|>` (token ID: 151652)
- `<|image_pad|>` x N (token ID: 151655) - æ•°é‡å–å†³äºå›¾åƒçš„ patches æ•°é‡
- `<|vision_end|>` (token ID: 151653)

**æˆ‘ä»¬çš„æ•°æ®ç®¡é“é—®é¢˜**ï¼š
- æ–‡æœ¬é€šè¿‡ `tokenizer.encode(text)` å•ç‹¬å¤„ç†
- å›¾åƒé€šè¿‡ `image_processor.preprocess(image)` å•ç‹¬å¤„ç†
- **Qwen çš„ processor éœ€è¦åŒæ—¶æ¥æ”¶å›¾åƒå’Œæ–‡æœ¬æ‰èƒ½æ­£ç¡®æ’å…¥ vision tokensï¼**

## âœ… è§£å†³æ–¹æ¡ˆ

### æ–¹æ¡ˆæ¦‚è¿°

1. **ä¿®æ”¹ `QwenImageProcessorWrapper`**: è®©å®ƒå¤„ç†æ–‡æœ¬ï¼ˆåŒ…å« `<image>` placeholderï¼‰
2. **æå– vision tokens**: ä» processor ç”Ÿæˆçš„ `input_ids` ä¸­æå–
3. **æ’å…¥åˆ°æ•°æ®ç®¡é“**: åœ¨åŸæœ‰çš„ `input_ids` ä¸­æ›¿æ¢ `<image>` token

### è¯¦ç»†å®ç°

#### 1. ä¿®æ”¹ `flmm/datasets/qwen_image_processor.py`

**å…³é”®å˜æ›´**ï¼š

```python
def preprocess(self, image, text=None):
    # å¦‚æœæ²¡æœ‰æä¾›æ–‡æœ¬ï¼Œä½¿ç”¨ "<image>" placeholder
    if text is None or not text:
        processor_texts = ["<image>"] * len(images)
    else:
        processor_texts = texts
    
    # åŒæ—¶å¤„ç†å›¾åƒå’Œæ–‡æœ¬
    inputs = self.processor(
        text=processor_texts,
        images=images,
        return_tensors="pt",
        padding=False,
    )
    
    # æå–ç»“æœ
    pixel_values = inputs['pixel_values']
    image_grid_thw = inputs['image_grid_thw']
    input_ids_with_vision = inputs['input_ids']  # åŒ…å« vision tokens!
    
    # ... è¿”å›æ‰€æœ‰å†…å®¹
    result['input_ids_with_vision'] = [input_ids_np[i] for i in range(len(images))]
```

#### 2. ä¿®æ”¹ `flmm/datasets/transforms.py` å’Œ `flmm/datasets/png.py`

**å…³é”®å˜æ›´**ï¼š

```python
# å¤„ç†å®Œå›¾åƒå
image_data = self.image_processor.preprocess(image)

# æ£€æŸ¥æ˜¯å¦æœ‰ vision tokens
if 'input_ids_with_vision' in image_data:
    vision_input_ids = image_data['input_ids_with_vision'][0]
    
    # æå– vision tokens (ä» <|vision_start|> åˆ° <|vision_end|>)
    vision_start_id = 151652
    vision_end_id = 151653
    
    vision_start_idx = (vision_input_ids == vision_start_id).nonzero()[0]
    vision_end_idx = (vision_input_ids == vision_end_id).nonzero()[0]
    
    if len(vision_start_idx) > 0 and len(vision_end_idx) > 0:
        vision_tokens = vision_input_ids[vision_start_idx[0]:vision_end_idx[0]+1]
        
        # åœ¨ input_ids ä¸­æ‰¾åˆ° <image> token å¹¶æ›¿æ¢ä¸º vision tokens
        image_token_positions = (input_ids == self.image_token_idx).nonzero()[0]
        
        if len(image_token_positions) > 0:
            img_pos = image_token_positions[0]
            input_ids = torch.cat([
                input_ids[:img_pos],
                vision_tokens,
                input_ids[img_pos+1:]
            ])
            
            # åŒæ ·æ›´æ–° mask_ids
            vision_mask_ids = torch.full((len(vision_tokens),), -1)
            mask_ids = torch.cat([
                mask_ids[:img_pos],
                vision_mask_ids,
                mask_ids[img_pos+1:]
            ])
```

## ğŸ“Š ä¿®å¤æ•ˆæœ

### ä¿®å¤å‰

```
input_ids: [prompt_tokens] + [<image>] + [text_tokens]
                              ^^^^^^^^
                           å•ä¸ª tokenï¼Œæ²¡æœ‰ vision ä¿¡æ¯

æ¨¡å‹ï¼šæˆ‘çœ‹åˆ°äº†å›¾åƒç‰¹å¾ (252 ä¸ª)ï¼Œä½† input_ids ä¸­æ²¡æœ‰å¯¹åº”çš„ vision tokensï¼
ç»“æœï¼šValueError âŒ
```

### ä¿®å¤å

```
input_ids: [prompt_tokens] + [<|vision_start|>] + [<|image_pad|> x N] + [<|vision_end|>] + [text_tokens]
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                              æ­£ç¡®çš„ vision tokens (æ€»å…± N+2 ä¸ª)

æ¨¡å‹ï¼šinput_ids ä¸­æœ‰ N+2 ä¸ª vision tokensï¼ŒåŒ¹é…å›¾åƒç‰¹å¾ï¼
ç»“æœï¼šæ­£å¸¸å¤„ç† âœ…
```

## ğŸ¯ å…³é”®è¦ç‚¹

1. **Qwen çš„ç‰¹æ®Šæ€§**
   - å¿…é¡»åœ¨ `input_ids` ä¸­åŒ…å« vision tokens
   - ä¸èƒ½åªæä¾› `pixel_values` å’Œ `image_grid_thw`

2. **Processor çš„æ­£ç¡®ä½¿ç”¨**
   - å¿…é¡»åŒæ—¶ä¼ é€’å›¾åƒå’Œæ–‡æœ¬ï¼ˆå³ä½¿æ–‡æœ¬åªæ˜¯ "<image>"ï¼‰
   - Processor ä¼šè‡ªåŠ¨ç”Ÿæˆæ­£ç¡®çš„ vision tokens

3. **æ•°æ®ç®¡é“çš„é€‚é…**
   - æå– processor ç”Ÿæˆçš„ vision tokens
   - æ›¿æ¢åŸæœ‰ `input_ids` ä¸­çš„ `<image>` placeholder

## ğŸ§ª éªŒè¯

ç°åœ¨è¯·æµ‹è¯•ï¼š

```bash
cd F-LMM
xtuner train configs/qwen/frozen_qwen2_5_vl_3b_instruct_unet_sam_l_refcoco_png.py
```

**é¢„æœŸç»“æœ**ï¼š
- âœ… ä¸å†å‡ºç° "Image features and image tokens do not match"
- âœ… è®­ç»ƒæ­£å¸¸è¿›è¡Œ
- âœ… `input_ids` åŒ…å«æ­£ç¡®çš„ vision tokens

## ğŸ“š ç›¸å…³æ–‡ä»¶

### ä¿®æ”¹çš„æ–‡ä»¶
1. `flmm/datasets/qwen_image_processor.py` - æ·»åŠ textå‚æ•°ï¼Œæå–input_ids_with_vision
2. `flmm/datasets/transforms.py` - æ’å…¥ vision tokens
3. `flmm/datasets/png.py` - æ’å…¥ vision tokens

### ç›¸å…³æ–‡æ¡£
- `tests/CRITICAL_FIX_CN.md` - pixel_values æ ¼å¼ä¿®å¤
- `tests/FIX_SUMMARY_CN.md` - åŸå§‹ image_grid_thw ä¿®å¤
- `tests/QWEN_PIXEL_VALUES_FORMAT.md` - Qwen æ ¼å¼è¯´æ˜

---

**ä¿®å¤æ—¶é—´**: 2025-11-08 05:30+  
**å½±å“æ–‡ä»¶**: 3ä¸ª  
**ä¸¥é‡æ€§**: ğŸ”¥ å…³é”®ï¼ˆblockingè®­ç»ƒï¼‰  
**çŠ¶æ€**: âœ… å·²ä¿®å¤ï¼Œç­‰å¾…éªŒè¯

## ğŸ‰ è¿›å±•æ€»ç»“

ä»æœ€åˆçš„é”™è¯¯åˆ°ç°åœ¨ï¼Œæˆ‘ä»¬å·²ç»ä¿®å¤äº†ï¼š
1. âœ… `image_grid_thw` ç¼ºå¤±é—®é¢˜
2. âœ… pixel_values æ ¼å¼è¯¯è§£é—®é¢˜
3. âœ… vision tokens ç¼ºå¤±é—®é¢˜

ç°åœ¨åº”è¯¥å¯ä»¥æ­£å¸¸è®­ç»ƒäº†ï¼ğŸš€

