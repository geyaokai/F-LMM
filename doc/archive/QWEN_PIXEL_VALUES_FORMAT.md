# Qwen2.5-VL çš„ pixel_values æ ¼å¼è¯´æ˜

## ğŸ” é‡è¦å‘ç°

é€šè¿‡æµ‹è¯•å‘ç°ï¼Œ**Qwen2.5-VL çš„ processor è¿”å›çš„ `pixel_values` æ ¼å¼ä¸å…¶ä»–æ¨¡å‹ä¸åŒ**ï¼

## ğŸ“Š æ ¼å¼å¯¹æ¯”

### æ ‡å‡†æ ¼å¼ï¼ˆå¤§å¤šæ•°è§†è§‰æ¨¡å‹ï¼‰
```python
# DeepSeek-VL, LLaVA, LLaVA-NeXT ç­‰
pixel_values.shape = torch.Size([batch, channels, height, width])
# ä¾‹å¦‚: torch.Size([1, 3, 224, 224])
```

### Qwen2.5-VL æ ¼å¼
```python
# Qwen2.5-VL ä½¿ç”¨æ‰å¹³åŒ–çš„ 2D æ ¼å¼
pixel_values.shape = torch.Size([height, width])
# ä¾‹å¦‚: torch.Size([1564, 1176])
# æˆ–: torch.Size([256, 1176])
```

## ğŸ§ª å®é™…æµ‹è¯•ç»“æœ

### æµ‹è¯• 1: 224Ã—224 å›¾åƒ
```
è¾“å…¥: PIL.Image (224, 224)
è¾“å‡º: pixel_values.shape = torch.Size([256, 1176])
æ³¨æ„: ä¸æ˜¯ [1, 3, 224, 224]ï¼
```

### æµ‹è¯• 2: 640Ã—480 å›¾åƒ
```
è¾“å…¥: PIL.Image (640, 480)
è¾“å‡º: pixel_values.shape = torch.Size([1564, 1176])
```

### æµ‹è¯• 3: 448Ã—224 å®½çŸ©å½¢
```
è¾“å…¥: PIL.Image (448, 224)
è¾“å‡º: pixel_values.shape = torch.Size([512, 1176])
```

## ğŸ’¡ ä¸ºä»€ä¹ˆè¿™æ ·è®¾è®¡ï¼Ÿ

Qwen2.5-VL ä½¿ç”¨äº†**å¯å˜åˆ†è¾¨ç‡çš„è§†è§‰ç¼–ç å™¨**ï¼š

1. **åŠ¨æ€åˆ†è¾¨ç‡**ï¼šä¸å°†å›¾åƒ resize åˆ°å›ºå®šå¤§å°
2. **ä¿æŒå®½é«˜æ¯”**ï¼šæ·»åŠ  padding è€Œéæ‹‰ä¼¸
3. **æ‰å¹³åŒ–è¡¨ç¤º**ï¼šå°†å›¾åƒè¡¨ç¤ºä¸º token åºåˆ—
4. **é…åˆ image_grid_thw**ï¼šé€šè¿‡ grid_thw æ¢å¤ç©ºé—´ç»“æ„

## ğŸ”§ åœ¨æ¨¡å‹ä¸­çš„å¤„ç†

### åœ¨ frozen_qwen.py ä¸­éœ€è¦æ³¨æ„

```python
# âŒ é”™è¯¯çš„å‡è®¾
pixel_values = data_sample['pixel_values']  # å‡è®¾æ˜¯ [B, C, H, W]
_, c, h, w = pixel_values.shape  # ğŸ’¥ ä¼šæŠ¥é”™ï¼

# âœ… æ­£ç¡®çš„å¤„ç†
pixel_values = data_sample['pixel_values']
if pixel_values.dim() == 4:
    _, _, h, w = pixel_values.shape
elif pixel_values.dim() == 3:
    _, h, w = pixel_values.shape
elif pixel_values.dim() == 2:
    h, w = pixel_values.shape
else:
    raise ValueError(f"Unexpected pixel_values shape: {pixel_values.shape}")
```

### ä¼ é€’ç»™æ¨¡å‹

```python
# Qwen æ¨¡å‹ä¼šè‡ªåŠ¨å¤„ç†è¿™ç§æ ¼å¼
model_kwargs = {
    'pixel_values': pixel_values.to(device),  # ä¿æŒåŸæ ¼å¼
    'image_grid_thw': image_grid_thw,  # æä¾›ç©ºé—´ä¿¡æ¯
    'input_ids': input_ids,
}
outputs = qwen_model(**model_kwargs)
```

## ğŸ“ ç»´åº¦è§£é‡Š

### ä¸ºä»€ä¹ˆæ˜¯ [1564, 1176] è€Œä¸æ˜¯ [1, 3, H, W]ï¼Ÿ

è¿™æ˜¯ Qwen çš„**å†…éƒ¨è¡¨ç¤ºæ ¼å¼**ï¼š

1. **1564**ï¼šè¡¨ç¤ºå›¾åƒ token çš„æ•°é‡æˆ–æŸç§ç¼–ç åçš„é«˜åº¦
2. **1176**ï¼šå¯èƒ½æ˜¯ç‰¹å¾ç»´åº¦æˆ–ç¼–ç åçš„å®½åº¦
3. **ä¸åŒ…å« batch ç»´åº¦**ï¼šåœ¨åºåˆ—çº§åˆ«å¤„ç†
4. **ä¸åŒ…å« channel ç»´åº¦**ï¼šå·²ç»ç¼–ç 

### å¦‚ä½•æ¢å¤ç©ºé—´ä¿¡æ¯ï¼Ÿ

é€šè¿‡ `image_grid_thw` å‚æ•°ï¼š

```python
# å¯¹äº 640Ã—480 çš„å›¾åƒ
pixel_values.shape = torch.Size([1564, 1176])
image_grid_thw = tensor([[1, 34, 46]])

# è§£é‡Šï¼š
# - temporal = 1 (å•å¸§å›¾åƒ)
# - grid_h = 34 (é«˜åº¦æ–¹å‘çš„ patch æ•°é‡)
# - grid_w = 46 (å®½åº¦æ–¹å‘çš„ patch æ•°é‡)
# - æ€» patches = 34 Ã— 46 = 1564 âœ“
```

## âš ï¸ å¸¸è§é”™è¯¯

### é”™è¯¯ 1ï¼šå‡è®¾æ˜¯ 4D tensor
```python
# âŒ ä¼šå¤±è´¥
b, c, h, w = pixel_values.shape
```

### é”™è¯¯ 2ï¼šå°è¯• unsqueeze
```python
# âŒ å¯èƒ½ç ´åæ ¼å¼
pixel_values = pixel_values.unsqueeze(0)  # ä¸è¦è¿™æ ·åšï¼
```

### é”™è¯¯ 3ï¼šæ‰‹åŠ¨ reshape
```python
# âŒ å¯èƒ½å¯¼è‡´æ•°æ®é”™è¯¯
pixel_values = pixel_values.view(1, 3, h, w)  # ä¸è¦å‡è®¾ç»“æ„ï¼
```

## âœ… æ­£ç¡®åšæ³•

### åœ¨ Dataset ä¸­
```python
# ç›´æ¥ä½¿ç”¨ processor çš„è¾“å‡º
inputs = processor(
    text=[formatted_text],
    images=[image],
    return_tensors="pt"
)

data_sample = {
    'pixel_values': inputs['pixel_values'],  # ä¿æŒåŸæ ¼å¼
    'image_grid_thw': inputs['image_grid_thw'],  # å¿…éœ€ï¼
    'input_ids': inputs['input_ids'][0],
    # ...
}
```

### åœ¨æ¨¡å‹ä¸­
```python
# ç›´æ¥ä¼ é€’ï¼Œè®© Qwen æ¨¡å‹å¤„ç†
model_kwargs = {
    'pixel_values': pixel_values.to(device),
    'image_grid_thw': image_grid_thw.to(device),
    'input_ids': input_ids.to(device),
}
outputs = qwen_model(**model_kwargs)
```

## ğŸ”¬ æ·±å…¥åˆ†æ

### ä¸ DeepSeek-VL å¯¹æ¯”

| ç‰¹æ€§ | DeepSeek-VL | Qwen2.5-VL |
|------|-------------|------------|
| pixel_values æ ¼å¼ | `[1, 1, 3, 384, 384]` | `[H_tokens, W_features]` |
| ç»´åº¦æ•°é‡ | 5D | 2D |
| åŒ…å« batch | âœ“ | âœ— |
| åŒ…å« channel | âœ“ | âœ—ï¼ˆå·²ç¼–ç ï¼‰ |
| åˆ†è¾¨ç‡ | å›ºå®š 384Ã—384 | åŠ¨æ€ |
| éœ€è¦ grid_thw | âœ— | âœ“ |

### ä¸ºä»€ä¹ˆéœ€è¦ image_grid_thwï¼Ÿ

å› ä¸º pixel_values æ˜¯æ‰å¹³åŒ–çš„ï¼Œ**å¿…é¡»é€šè¿‡ image_grid_thw æ‰èƒ½æ¢å¤ç©ºé—´ç»“æ„**ï¼š

```python
# æ²¡æœ‰ grid_thwï¼Œæ¨¡å‹æ— æ³•çŸ¥é“ï¼š
# - å›¾åƒçš„åŸå§‹å°ºå¯¸
# - patch çš„ç©ºé—´å¸ƒå±€
# - å¦‚ä½•åº”ç”¨ä½ç½®ç¼–ç 

# è¿™å°±æ˜¯ä¸ºä»€ä¹ˆ grid_thw=None ä¼šå¯¼è‡´é”™è¯¯ï¼š
# TypeError: 'NoneType' object is not iterable
```

## ğŸ“ æµ‹è¯•éªŒè¯

è¿è¡Œä»¥ä¸‹æµ‹è¯•æ¥éªŒè¯æ ¼å¼ï¼š

```bash
cd /home/cvprtemp/gyk/F-LMM/tests
python diagnose_image_grid_thw.py
```

åº”è¯¥çœ‹åˆ°ï¼š
```
pixel_values: shape=torch.Size([1564, 1176])  â† 2Dï¼Œä¸æ˜¯ 4D
image_grid_thw: tensor([[ 1, 34, 46]])        â† å¿…éœ€çš„ç©ºé—´ä¿¡æ¯
```

## ğŸ¯ æ€»ç»“

1. âœ… **Qwen2.5-VL ä½¿ç”¨ 2D pixel_values æ ¼å¼**
2. âœ… **ä¸è¦å‡è®¾æ˜¯æ ‡å‡†çš„ [B, C, H, W] æ ¼å¼**
3. âœ… **å¿…é¡»æä¾› image_grid_thw æ¥æ¢å¤ç©ºé—´ä¿¡æ¯**
4. âœ… **ç›´æ¥ä¼ é€’ç»™æ¨¡å‹ï¼Œä¸è¦æ‰‹åŠ¨ reshape**
5. âœ… **åœ¨å¤„ç†ç»´åº¦æ—¶ä½¿ç”¨çµæ´»çš„é€»è¾‘**

## ğŸ”— ç›¸å…³æ–‡ä»¶

- `tests/test_frozen_qwen.py` - åŒ…å«æ ¼å¼éªŒè¯æµ‹è¯•
- `flmm/models/frozen_qwen.py` - æ¨¡å‹å®ç°ï¼ˆå·²è€ƒè™‘å¤šç§ç»´åº¦ï¼‰
- `tests/diagnose_image_grid_thw.py` - è¯Šæ–­å·¥å…·

